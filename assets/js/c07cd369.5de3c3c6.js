"use strict";(globalThis.webpackChunkphysical_ai_textbook=globalThis.webpackChunkphysical_ai_textbook||[]).push([[5640],{4802:(n,r,e)=>{e.r(r),e.d(r,{assets:()=>o,contentTitle:()=>t,default:()=>d,frontMatter:()=>l,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"module-03-isaac/slam-basics","title":"Chapter 4: SLAM Basics","description":"What is SLAM?","source":"@site/docs/module-03-isaac/04-slam-basics.md","sourceDirName":"module-03-isaac","slug":"/module-03-isaac/slam-basics","permalink":"/physical-ai-textbook/docs/module-03-isaac/slam-basics","draft":false,"unlisted":false,"editUrl":"https://github.com/Zeenat-Somroo911/physical-ai-textbook/edit/main/docs/module-03-isaac/04-slam-basics.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 3: Computer Vision with OpenCV","permalink":"/physical-ai-textbook/docs/module-03-isaac/computer-vision"},"next":{"title":"Chapter 5: Navigation with Nav2","permalink":"/physical-ai-textbook/docs/module-03-isaac/navigation"}}');var i=e(4848),s=e(8453);const l={sidebar_position:4},t="Chapter 4: SLAM Basics",o={},c=[{value:"What is SLAM?",id:"what-is-slam",level:2},{value:"Why SLAM?",id:"why-slam",level:3},{value:"SLAM Process",id:"slam-process",level:3},{value:"ORB-SLAM3 Setup",id:"orb-slam3-setup",level:2},{value:"Installation",id:"installation",level:3},{value:"Building ORB-SLAM3",id:"building-orb-slam3",level:3},{value:"Verify Installation",id:"verify-installation",level:3},{value:"ORB-SLAM3 Usage",id:"orb-slam3-usage",level:2},{value:"Monocular SLAM",id:"monocular-slam",level:3},{value:"Python Wrapper (pyORB_SLAM3)",id:"python-wrapper-pyorb_slam3",level:3},{value:"Python Example",id:"python-example",level:3},{value:"RTAB-Map for RGB-D SLAM",id:"rtab-map-for-rgb-d-slam",level:2},{value:"Installation",id:"installation-1",level:3},{value:"RTAB-Map with ROS 2",id:"rtab-map-with-ros-2",level:3},{value:"RTAB-Map Launch File",id:"rtab-map-launch-file",level:3},{value:"Map Building",id:"map-building",level:2},{value:"Building Maps with ORB-SLAM3",id:"building-maps-with-orb-slam3",level:3},{value:"Loading Saved Maps",id:"loading-saved-maps",level:3},{value:"Complete Example with ROS 2",id:"complete-example-with-ros-2",level:2},{value:"SLAM Node",id:"slam-node",level:3},{value:"Visualization",id:"visualization",level:2},{value:"Viewing Maps in RViz2",id:"viewing-maps-in-rviz2",level:3},{value:"Map Visualization",id:"map-visualization",level:3},{value:"Best Practices",id:"best-practices",level:2},{value:"Common Errors and Solutions",id:"common-errors-and-solutions",level:2},{value:"Error 1: &quot;ORB-SLAM3 build fails&quot;",id:"error-1-orb-slam3-build-fails",level:3},{value:"Error 2: &quot;No features detected&quot;",id:"error-2-no-features-detected",level:3},{value:"Error 3: &quot;Tracking lost&quot;",id:"error-3-tracking-lost",level:3},{value:"Next Steps",id:"next-steps",level:2}];function p(n){const r={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...n.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(r.header,{children:(0,i.jsx)(r.h1,{id:"chapter-4-slam-basics",children:"Chapter 4: SLAM Basics"})}),"\n",(0,i.jsx)(r.h2,{id:"what-is-slam",children:"What is SLAM?"}),"\n",(0,i.jsx)(r.p,{children:"SLAM (Simultaneous Localization and Mapping) is a technique that allows robots to build a map of an unknown environment while simultaneously tracking their location within that map. It's essential for autonomous navigation."}),"\n",(0,i.jsx)(r.h3,{id:"why-slam",children:"Why SLAM?"}),"\n",(0,i.jsxs)(r.ul,{children:["\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.strong,{children:"Unknown Environments"}),": Navigate without prior maps"]}),"\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.strong,{children:"Localization"}),": Know where you are"]}),"\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.strong,{children:"Mapping"}),": Build maps for future use"]}),"\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.strong,{children:"Autonomy"}),": Enable fully autonomous robots"]}),"\n"]}),"\n",(0,i.jsx)(r.h3,{id:"slam-process",children:"SLAM Process"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-mermaid",children:"graph TB\r\n    A[Robot Starts] --\x3e B[Capture Sensor Data]\r\n    B --\x3e C[Extract Features]\r\n    C --\x3e D[Match Features]\r\n    D --\x3e E[Estimate Motion]\r\n    E --\x3e F[Update Map]\r\n    F --\x3e G[Update Pose]\r\n    G --\x3e B\r\n    \r\n    style A fill:#e1f5ff\r\n    style F fill:#c8e6c9\r\n    style G fill:#fff9c4\n"})}),"\n",(0,i.jsx)(r.h2,{id:"orb-slam3-setup",children:"ORB-SLAM3 Setup"}),"\n",(0,i.jsx)(r.p,{children:"ORB-SLAM3 is a state-of-the-art SLAM system, completely free and open-source."}),"\n",(0,i.jsx)(r.h3,{id:"installation",children:"Installation"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-bash",children:"# Install dependencies\r\nsudo apt update\r\nsudo apt install -y \\\r\n    cmake \\\r\n    git \\\r\n    libeigen3-dev \\\r\n    libopencv-dev \\\r\n    libpangolin-dev \\\r\n    python3-dev \\\r\n    python3-numpy\r\n\r\n# Install Pangolin (visualization)\r\ncd ~\r\ngit clone https://github.com/stevenlovegrove/Pangolin.git\r\ncd Pangolin\r\nmkdir build && cd build\r\ncmake ..\r\nmake -j4\r\nsudo make install\r\n\r\n# Install ORB-SLAM3\r\ncd ~\r\ngit clone https://github.com/UZ-SLAMLab/ORB_SLAM3.git\r\ncd ORB_SLAM3\r\nchmod +x build.sh\r\n./build.sh\n"})}),"\n",(0,i.jsx)(r.h3,{id:"building-orb-slam3",children:"Building ORB-SLAM3"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-bash",children:"cd ~/ORB_SLAM3\r\n./build.sh\r\n\r\n# If build fails, try:\r\nmkdir build\r\ncd build\r\ncmake ..\r\nmake -j4\n"})}),"\n",(0,i.jsx)(r.h3,{id:"verify-installation",children:"Verify Installation"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-bash",children:"# Check if executable exists\r\nls ~/ORB_SLAM3/Examples/Monocular/mono_euroc\r\n\r\n# Test with sample data\r\ncd ~/ORB_SLAM3\r\n./Examples/Monocular/mono_euroc \\\r\n    Vocabulary/ORBvoc.txt \\\r\n    Examples/Monocular/EuRoC.yaml \\\r\n    /path/to/EuRoC/dataset\n"})}),"\n",(0,i.jsx)(r.h2,{id:"orb-slam3-usage",children:"ORB-SLAM3 Usage"}),"\n",(0,i.jsx)(r.h3,{id:"monocular-slam",children:"Monocular SLAM"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-cpp",children:'// Example C++ usage\r\n#include "System.h"\r\n#include <opencv2/opencv.hpp>\r\n\r\nint main(int argc, char **argv) {\r\n    // Initialize ORB-SLAM3\r\n    ORB_SLAM3::System SLAM(\r\n        argv[1],  // Vocabulary file\r\n        argv[2],  // Settings file\r\n        ORB_SLAM3::System::MONOCULAR,\r\n        true      // Use viewer\r\n    );\r\n    \r\n    cv::VideoCapture cap(0);\r\n    cv::Mat frame;\r\n    \r\n    while (cap.read(frame)) {\r\n        // Track frame\r\n        SLAM.TrackMonocular(frame, timestamp);\r\n    }\r\n    \r\n    SLAM.Shutdown();\r\n    return 0;\r\n}\n'})}),"\n",(0,i.jsx)(r.h3,{id:"python-wrapper-pyorb_slam3",children:"Python Wrapper (pyORB_SLAM3)"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-bash",children:"# Install Python wrapper\r\npip install pyorbslam3\r\n\r\n# Or build from source\r\ngit clone https://github.com/jingpang/pyORB_SLAM3.git\r\ncd pyORB_SLAM3\r\npython setup.py install\n"})}),"\n",(0,i.jsx)(r.h3,{id:"python-example",children:"Python Example"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-python",children:'#!/usr/bin/env python3\r\n"""\r\nORB-SLAM3 Python Example\r\n\r\nRun SLAM with webcam.\r\n"""\r\n\r\nimport cv2\r\nimport pyorbslam3\r\n\r\n# Initialize SLAM\r\nvocab_path = "Vocabulary/ORBvoc.txt"\r\nsettings_path = "Examples/Monocular/TUM1.yaml"\r\nslam = pyorbslam3.System(vocab_path, settings_path, pyorbslam3.System.MONOCULAR, True)\r\n\r\n# Open camera\r\ncap = cv2.VideoCapture(0)\r\n\r\ntimestamp = 0.0\r\n\r\nwhile True:\r\n    ret, frame = cap.read()\r\n    if not ret:\r\n        break\r\n    \r\n    # Track frame\r\n    slam.TrackMonocular(frame, timestamp)\r\n    \r\n    timestamp += 1.0/30.0  # 30 FPS\r\n    \r\n    if cv2.waitKey(1) & 0xFF == ord(\'q\'):\r\n        break\r\n\r\nslam.Shutdown()\r\ncap.release()\n'})}),"\n",(0,i.jsx)(r.h2,{id:"rtab-map-for-rgb-d-slam",children:"RTAB-Map for RGB-D SLAM"}),"\n",(0,i.jsx)(r.p,{children:"RTAB-Map is another excellent free SLAM system, especially good for RGB-D cameras."}),"\n",(0,i.jsx)(r.h3,{id:"installation-1",children:"Installation"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-bash",children:"# Install RTAB-Map\r\nsudo apt install ros-humble-rtabmap-ros\r\n\r\n# Or build from source\r\ncd ~\r\ngit clone https://github.com/introlab/rtabmap.git\r\ncd rtabmap/build\r\ncmake ..\r\nmake -j4\r\nsudo make install\n"})}),"\n",(0,i.jsx)(r.h3,{id:"rtab-map-with-ros-2",children:"RTAB-Map with ROS 2"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-python",children:'#!/usr/bin/env python3\r\n"""\r\nRTAB-Map ROS 2 Node\r\n\r\nRun RTAB-Map SLAM with ROS 2.\r\n"""\r\n\r\nimport rclpy\r\nfrom rclpy.node import Node\r\nfrom sensor_msgs.msg import Image, CameraInfo\r\nfrom geometry_msgs.msg import TransformStamped\r\nimport tf2_ros\r\n\r\nclass RTABMapNode(Node):\r\n    def __init__(self):\r\n        super().__init__(\'rtabmap_node\')\r\n        \r\n        # Subscribers\r\n        self.rgb_sub = self.create_subscription(\r\n            Image,\r\n            \'/camera/rgb/image_raw\',\r\n            self.rgb_callback,\r\n            10\r\n        )\r\n        \r\n        self.depth_sub = self.create_subscription(\r\n            Image,\r\n            \'/camera/depth/image_raw\',\r\n            self.depth_callback,\r\n            10\r\n        )\r\n        \r\n        self.camera_info_sub = self.create_subscription(\r\n            CameraInfo,\r\n            \'/camera/rgb/camera_info\',\r\n            self.camera_info_callback,\r\n            10\r\n        )\r\n        \r\n        self.get_logger().info(\'RTAB-Map node started\')\r\n    \r\n    def rgb_callback(self, msg):\r\n        """Process RGB image."""\r\n        # Process image for RTAB-Map\r\n        pass\r\n    \r\n    def depth_callback(self, msg):\r\n        """Process depth image."""\r\n        # Process depth for RTAB-Map\r\n        pass\r\n    \r\n    def camera_info_callback(self, msg):\r\n        """Process camera info."""\r\n        # Store camera parameters\r\n        pass\r\n\r\ndef main(args=None):\r\n    rclpy.init(args=args)\r\n    node = RTABMapNode()\r\n    rclpy.spin(node)\r\n    node.destroy_node()\r\n    rclpy.shutdown()\r\n\r\nif __name__ == \'__main__\':\r\n    main()\n'})}),"\n",(0,i.jsx)(r.h3,{id:"rtab-map-launch-file",children:"RTAB-Map Launch File"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-python",children:"from launch import LaunchDescription\r\nfrom launch_ros.actions import Node\r\n\r\ndef generate_launch_description():\r\n    return LaunchDescription([\r\n        # RTAB-Map node\r\n        Node(\r\n            package='rtabmap_ros',\r\n            executable='rtabmap',\r\n            name='rtabmap',\r\n            parameters=[{\r\n                'frame_id': 'base_link',\r\n                'odom_frame_id': 'odom',\r\n                'map_frame_id': 'map',\r\n                'use_sim_time': False\r\n            }],\r\n            remappings=[\r\n                ('rgb/image', '/camera/rgb/image_raw'),\r\n                ('depth/image', '/camera/depth/image_raw'),\r\n                ('rgb/camera_info', '/camera/rgb/camera_info')\r\n            ]\r\n        )\r\n    ])\n"})}),"\n",(0,i.jsx)(r.h2,{id:"map-building",children:"Map Building"}),"\n",(0,i.jsx)(r.h3,{id:"building-maps-with-orb-slam3",children:"Building Maps with ORB-SLAM3"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-python",children:'#!/usr/bin/env python3\r\n"""\r\nMap Building with ORB-SLAM3\r\n\r\nBuild and save maps.\r\n"""\r\n\r\nimport cv2\r\nimport pyorbslam3\r\nimport numpy as np\r\n\r\n# Initialize SLAM\r\nvocab_path = "Vocabulary/ORBvoc.txt"\r\nsettings_path = "Examples/Monocular/TUM1.yaml"\r\nslam = pyorbslam3.System(vocab_path, settings_path, pyorbslam3.System.MONOCULAR, True)\r\n\r\ncap = cv2.VideoCapture(0)\r\ntimestamp = 0.0\r\nmap_points = []\r\n\r\nwhile True:\r\n    ret, frame = cap.read()\r\n    if not ret:\r\n        break\r\n    \r\n    # Track frame\r\n    slam.TrackMonocular(frame, timestamp)\r\n    \r\n    # Get map points\r\n    current_map = slam.GetMapPoints()\r\n    if current_map:\r\n        map_points = current_map\r\n    \r\n    timestamp += 1.0/30.0\r\n    \r\n    # Visualize\r\n    cv2.imshow(\'SLAM\', frame)\r\n    \r\n    if cv2.waitKey(1) & 0xFF == ord(\'q\'):\r\n        break\r\n\r\n# Save map\r\nslam.SaveMap("map.bin")\r\nprint(f"Map saved with {len(map_points)} points")\r\n\r\nslam.Shutdown()\r\ncap.release()\n'})}),"\n",(0,i.jsx)(r.h3,{id:"loading-saved-maps",children:"Loading Saved Maps"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-python",children:'# Load map\r\nslam = pyorbslam3.System(vocab_path, settings_path, pyorbslam3.System.MONOCULAR, True)\r\nslam.LoadMap("map.bin")\n'})}),"\n",(0,i.jsx)(r.h2,{id:"complete-example-with-ros-2",children:"Complete Example with ROS 2"}),"\n",(0,i.jsx)(r.h3,{id:"slam-node",children:"SLAM Node"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-python",children:"#!/usr/bin/env python3\r\n\"\"\"\r\nComplete SLAM System\r\n\r\nORB-SLAM3 integrated with ROS 2.\r\n\"\"\"\r\n\r\nimport rclpy\r\nfrom rclpy.node import Node\r\nfrom sensor_msgs.msg import Image\r\nfrom nav_msgs.msg import OccupancyGrid, MapMetaData\r\nfrom geometry_msgs.msg import PoseWithCovarianceStamped\r\nfrom cv_bridge import CvBridge\r\nimport cv2\r\nimport numpy as np\r\n\r\n# Note: This is a conceptual example\r\n# Actual ORB-SLAM3 ROS 2 integration may require C++ wrapper\r\n\r\nclass SLAMNode(Node):\r\n    def __init__(self):\r\n        super().__init__('slam_node')\r\n        \r\n        self.bridge = CvBridge()\r\n        \r\n        # Initialize SLAM (pseudo-code)\r\n        # self.slam = initialize_slam()\r\n        \r\n        # Subscribers\r\n        self.image_sub = self.create_subscription(\r\n            Image,\r\n            '/camera/image_raw',\r\n            self.image_callback,\r\n            10\r\n        )\r\n        \r\n        # Publishers\r\n        self.map_pub = self.create_publisher(\r\n            OccupancyGrid,\r\n            '/map',\r\n            10\r\n        )\r\n        \r\n        self.pose_pub = self.create_publisher(\r\n            PoseWithCovarianceStamped,\r\n            '/slam_pose',\r\n            10\r\n        )\r\n        \r\n        self.get_logger().info('SLAM node started')\r\n    \r\n    def image_callback(self, msg):\r\n        \"\"\"Process image for SLAM.\"\"\"\r\n        try:\r\n            # Convert to OpenCV\r\n            cv_image = self.bridge.imgmsg_to_cv2(msg, \"bgr8\")\r\n            \r\n            # Process with SLAM\r\n            # pose = self.slam.process_frame(cv_image)\r\n            # map_data = self.slam.get_map()\r\n            \r\n            # Publish pose\r\n            pose_msg = PoseWithCovarianceStamped()\r\n            pose_msg.header = msg.header\r\n            # pose_msg.pose = pose\r\n            self.pose_pub.publish(pose_msg)\r\n            \r\n            # Publish map\r\n            map_msg = OccupancyGrid()\r\n            map_msg.header = msg.header\r\n            map_msg.info.resolution = 0.05  # 5cm per pixel\r\n            map_msg.info.width = 100\r\n            map_msg.info.height = 100\r\n            # map_msg.data = map_data\r\n            self.map_pub.publish(map_msg)\r\n        \r\n        except Exception as e:\r\n            self.get_logger().error(f'SLAM error: {e}')\r\n\r\ndef main(args=None):\r\n    rclpy.init(args=args)\r\n    node = SLAMNode()\r\n    \r\n    try:\r\n        rclpy.spin(node)\r\n    except KeyboardInterrupt:\r\n        node.get_logger().info('Shutting down...')\r\n    finally:\r\n        node.destroy_node()\r\n        rclpy.shutdown()\r\n\r\nif __name__ == '__main__':\r\n    main()\n"})}),"\n",(0,i.jsx)(r.h2,{id:"visualization",children:"Visualization"}),"\n",(0,i.jsx)(r.h3,{id:"viewing-maps-in-rviz2",children:"Viewing Maps in RViz2"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-bash",children:"# Launch RViz2\r\nrviz2\r\n\r\n# Add displays:\r\n# - Map (topic: /map)\r\n# - RobotModel\r\n# - TF\r\n# - Camera (topic: /camera/image_raw)\n"})}),"\n",(0,i.jsx)(r.h3,{id:"map-visualization",children:"Map Visualization"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-python",children:"import matplotlib.pyplot as plt\r\nimport numpy as np\r\n\r\n# Load map data\r\nmap_data = np.load('map.npy')\r\n\r\n# Visualize\r\nplt.figure(figsize=(10, 10))\r\nplt.imshow(map_data, cmap='gray')\r\nplt.colorbar()\r\nplt.title('SLAM Map')\r\nplt.show()\n"})}),"\n",(0,i.jsx)(r.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,i.jsxs)(r.ol,{children:["\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.strong,{children:"Good lighting"}),": SLAM works better with good lighting"]}),"\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.strong,{children:"Feature-rich scenes"}),": Avoid blank walls"]}),"\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.strong,{children:"Slow movement"}),": Move slowly for better tracking"]}),"\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.strong,{children:"Loop closure"}),": Return to known areas for map refinement"]}),"\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.strong,{children:"Save maps"}),": Save maps for reuse"]}),"\n"]}),"\n",(0,i.jsx)(r.h2,{id:"common-errors-and-solutions",children:"Common Errors and Solutions"}),"\n",(0,i.jsx)(r.h3,{id:"error-1-orb-slam3-build-fails",children:'Error 1: "ORB-SLAM3 build fails"'}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-bash",children:"# Solution: Install all dependencies\r\nsudo apt install libeigen3-dev libopencv-dev libpangolin-dev\n"})}),"\n",(0,i.jsx)(r.h3,{id:"error-2-no-features-detected",children:'Error 2: "No features detected"'}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-python",children:"# Solution: Check image quality, lighting, and scene content\r\n# Use feature-rich environments\n"})}),"\n",(0,i.jsx)(r.h3,{id:"error-3-tracking-lost",children:'Error 3: "Tracking lost"'}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-python",children:"# Solution: \r\n# - Move slower\r\n# - Ensure good lighting\r\n# - Use feature-rich scenes\r\n# - Check camera calibration\n"})}),"\n",(0,i.jsx)(r.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,i.jsx)(r.p,{children:"Continue learning:"}),"\n",(0,i.jsxs)(r.ul,{children:["\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.a,{href:"/physical-ai-textbook/docs/module-03-isaac/navigation",children:"Chapter 5: Navigation"})," - Navigate with Nav2"]}),"\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.a,{href:"/physical-ai-textbook/docs/module-03-isaac/perception-pipeline",children:"Chapter 6: Perception Pipeline"})," - Complete system"]}),"\n"]})]})}function d(n={}){const{wrapper:r}={...(0,s.R)(),...n.components};return r?(0,i.jsx)(r,{...n,children:(0,i.jsx)(p,{...n})}):p(n)}},8453:(n,r,e)=>{e.d(r,{R:()=>l,x:()=>t});var a=e(6540);const i={},s=a.createContext(i);function l(n){const r=a.useContext(s);return a.useMemo(function(){return"function"==typeof n?n(r):{...r,...n}},[r,n])}function t(n){let r;return r=n.disableParentContext?"function"==typeof n.components?n.components(i):n.components||i:l(n.components),a.createElement(s.Provider,{value:r},n.children)}}}]);