"use strict";(globalThis.webpackChunkphysical_ai_textbook=globalThis.webpackChunkphysical_ai_textbook||[]).push([[39],{4276:(n,e,r)=>{r.r(e),r.d(e,{assets:()=>c,contentTitle:()=>a,default:()=>p,frontMatter:()=>i,metadata:()=>t,toc:()=>l});const t=JSON.parse('{"id":"module-04-vla/llm-integration","title":"Chapter 3: LLM Integration","description":"OpenAI API Setup ($5 Free Credit)","source":"@site/docs/module-04-vla/03-llm-integration.md","sourceDirName":"module-04-vla","slug":"/module-04-vla/llm-integration","permalink":"/physical-ai-textbook/docs/module-04-vla/llm-integration","draft":false,"unlisted":false,"editUrl":"https://github.com/Zeenat-Somroo911/physical-ai-textbook/edit/main/docs/module-04-vla/03-llm-integration.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 2: Voice Commands","permalink":"/physical-ai-textbook/docs/module-04-vla/voice-commands"},"next":{"title":"Chapter 4: Action Planning","permalink":"/physical-ai-textbook/docs/module-04-vla/action-planning"}}');var o=r(4848),s=r(8453);const i={sidebar_position:3},a="Chapter 3: LLM Integration",c={},l=[{value:"OpenAI API Setup ($5 Free Credit)",id:"openai-api-setup-5-free-credit",level:2},{value:"Getting Started",id:"getting-started",level:3},{value:"Installation",id:"installation",level:3},{value:"Cost Breakdown",id:"cost-breakdown",level:3},{value:"Prompt Engineering for Robots",id:"prompt-engineering-for-robots",level:2},{value:"Basic Prompt Structure",id:"basic-prompt-structure",level:3},{value:"Advanced Prompting Techniques",id:"advanced-prompting-techniques",level:3},{value:"1. Few-Shot Learning",id:"1-few-shot-learning",level:4},{value:"2. Chain of Thought",id:"2-chain-of-thought",level:4},{value:"3. Constrained Output",id:"3-constrained-output",level:4},{value:"Converting Language to Actions",id:"converting-language-to-actions",level:2},{value:"Action Parser",id:"action-parser",level:3},{value:"Function Calling",id:"function-calling",level:2},{value:"Setup Function Calling",id:"setup-function-calling",level:3},{value:"Complete Working System",id:"complete-working-system",level:2},{value:"Full VLA System with LLM",id:"full-vla-system-with-llm",level:3},{value:"Cost Optimization Tips",id:"cost-optimization-tips",level:2},{value:"1. Use GPT-3.5-turbo",id:"1-use-gpt-35-turbo",level:3},{value:"2. Cache Common Queries",id:"2-cache-common-queries",level:3},{value:"3. Reduce Token Usage",id:"3-reduce-token-usage",level:3},{value:"4. Batch Requests",id:"4-batch-requests",level:3},{value:"5. Monitor Usage",id:"5-monitor-usage",level:3},{value:"Performance Benchmarks",id:"performance-benchmarks",level:2},{value:"Response Times",id:"response-times",level:3},{value:"Cost per Session",id:"cost-per-session",level:3},{value:"Best Practices",id:"best-practices",level:2},{value:"Common Errors and Solutions",id:"common-errors-and-solutions",level:2},{value:"Error 1: &quot;API key not set&quot;",id:"error-1-api-key-not-set",level:3},{value:"Error 2: &quot;Rate limit exceeded&quot;",id:"error-2-rate-limit-exceeded",level:3},{value:"Error 3: &quot;Invalid JSON response&quot;",id:"error-3-invalid-json-response",level:3},{value:"Next Steps",id:"next-steps",level:2}];function d(n){const e={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...n.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(e.header,{children:(0,o.jsx)(e.h1,{id:"chapter-3-llm-integration",children:"Chapter 3: LLM Integration"})}),"\n",(0,o.jsx)(e.h2,{id:"openai-api-setup-5-free-credit",children:"OpenAI API Setup ($5 Free Credit)"}),"\n",(0,o.jsx)(e.p,{children:"OpenAI provides $5 in free credit when you sign up, which is more than enough to learn and prototype VLA systems."}),"\n",(0,o.jsx)(e.h3,{id:"getting-started",children:"Getting Started"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Sign Up"}),": Go to ",(0,o.jsx)(e.a,{href:"https://platform.openai.com/signup",children:"https://platform.openai.com/signup"})]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Get API Key"}),": Navigate to API Keys section"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Add Payment"}),": Add $5 (or use free credit)"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Set Up"}),": Install library and configure"]}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"installation",children:"Installation"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-bash",children:"# Install OpenAI library\r\npip install openai\r\n\r\n# Set API key\r\nexport OPENAI_API_KEY=\"sk-your-key-here\"\r\n\r\n# Or in Python\r\nimport os\r\nos.environ['OPENAI_API_KEY'] = 'sk-your-key-here'\n"})}),"\n",(0,o.jsx)(e.h3,{id:"cost-breakdown",children:"Cost Breakdown"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{children:"GPT-3.5-turbo:    $0.002 per 1K tokens (input)\r\n                  $0.002 per 1K tokens (output)\r\n\r\nWith $5 credit:\r\n- ~2.5M input tokens\r\n- ~2.5M output tokens\r\n- Enough for 1000+ conversations\n"})}),"\n",(0,o.jsx)(e.h2,{id:"prompt-engineering-for-robots",children:"Prompt Engineering for Robots"}),"\n",(0,o.jsx)(e.p,{children:"Effective prompts are crucial for getting robots to understand and execute commands correctly."}),"\n",(0,o.jsx)(e.h3,{id:"basic-prompt-structure",children:"Basic Prompt Structure"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'import openai\r\n\r\ndef create_robot_prompt(user_command, robot_state):\r\n    """Create prompt for robot command."""\r\n    prompt = f"""You are a robot assistant. Convert the user\'s natural language command into robot actions.\r\n\r\nCurrent robot state:\r\n- Position: {robot_state[\'position\']}\r\n- Battery: {robot_state[\'battery\']}%\r\n- Status: {robot_state[\'status\']}\r\n\r\nUser command: {user_command}\r\n\r\nRespond with a JSON object containing:\r\n- action: The action to perform (move, pick, place, etc.)\r\n- parameters: Action parameters (direction, distance, object, etc.)\r\n- reasoning: Brief explanation\r\n\r\nExample response:\r\n{{\r\n    "action": "move",\r\n    "parameters": {{"direction": "forward", "distance": 1.0}},\r\n    "reasoning": "User wants to move forward 1 meter"\r\n}}\r\n"""\r\n    return prompt\n'})}),"\n",(0,o.jsx)(e.h3,{id:"advanced-prompting-techniques",children:"Advanced Prompting Techniques"}),"\n",(0,o.jsx)(e.h4,{id:"1-few-shot-learning",children:"1. Few-Shot Learning"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'def create_few_shot_prompt(command):\r\n    """Prompt with examples."""\r\n    prompt = f"""Convert natural language to robot actions.\r\n\r\nExamples:\r\n1. User: "Pick up the cup"\r\n   Response: {{"action": "pick", "object": "cup", "location": "detect"}}\r\n\r\n2. User: "Move forward 2 meters"\r\n   Response: {{"action": "move", "direction": "forward", "distance": 2.0}}\r\n\r\n3. User: "Turn left and stop"\r\n   Response: {{"action": "turn", "direction": "left", "angle": 90}}, {{"action": "stop"}}\r\n\r\nNow convert:\r\nUser: "{command}"\r\nResponse:"""\r\n    return prompt\n'})}),"\n",(0,o.jsx)(e.h4,{id:"2-chain-of-thought",children:"2. Chain of Thought"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'def create_cot_prompt(command):\r\n    """Prompt with reasoning steps."""\r\n    prompt = f"""Convert the command to robot actions. Think step by step.\r\n\r\nCommand: {command}\r\n\r\nStep 1: Understand what the user wants\r\nStep 2: Identify required actions\r\nStep 3: Determine parameters\r\nStep 4: Generate action sequence\r\n\r\nResponse format:\r\n{{\r\n    "steps": ["step1", "step2", ...],\r\n    "actions": [{{"action": "...", "params": {{...}}}}, ...]\r\n}}"""\r\n    return prompt\n'})}),"\n",(0,o.jsx)(e.h4,{id:"3-constrained-output",children:"3. Constrained Output"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'def create_constrained_prompt(command):\r\n    """Prompt with output constraints."""\r\n    prompt = f"""Convert command to robot action. Use ONLY these actions:\r\n- move(direction, distance)\r\n- turn(direction, angle)\r\n- pick(object)\r\n- place(object, location)\r\n- stop()\r\n\r\nCommand: {command}\r\n\r\nResponse (JSON only):"""\r\n    return prompt\n'})}),"\n",(0,o.jsx)(e.h2,{id:"converting-language-to-actions",children:"Converting Language to Actions"}),"\n",(0,o.jsx)(e.h3,{id:"action-parser",children:"Action Parser"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'#!/usr/bin/env python3\r\n"""\r\nLanguage to Action Converter\r\n\r\nConverts natural language to robot actions using OpenAI.\r\n"""\r\n\r\nimport openai\r\nimport rclpy\r\nfrom rclpy.node import Node\r\nfrom std_msgs.msg import String\r\nfrom geometry_msgs.msg import Twist\r\nimport json\r\n\r\nclass LanguageToAction(Node):\r\n    def __init__(self):\r\n        super().__init__(\'language_to_action\')\r\n        \r\n        # Set API key\r\n        openai.api_key = os.getenv(\'OPENAI_API_KEY\')\r\n        \r\n        # Subscriber\r\n        self.command_sub = self.create_subscription(\r\n            String,\r\n            \'/voice_command\',\r\n            self.command_callback,\r\n            10\r\n        )\r\n        \r\n        # Publishers\r\n        self.action_pub = self.create_publisher(String, \'/robot_action\', 10)\r\n        self.cmd_vel_pub = self.create_publisher(Twist, \'/cmd_vel\', 10)\r\n        \r\n        # Robot state\r\n        self.robot_state = {\r\n            \'position\': [0, 0, 0],\r\n            \'battery\': 100,\r\n            \'status\': \'idle\'\r\n        }\r\n        \r\n        self.get_logger().info(\'Language to action converter started\')\r\n    \r\n    def command_callback(self, msg):\r\n        """Process voice command."""\r\n        command = msg.data\r\n        self.get_logger().info(f\'Processing command: {command}\')\r\n        \r\n        # Convert to action\r\n        action = self.convert_to_action(command)\r\n        \r\n        if action:\r\n            self.execute_action(action)\r\n    \r\n    def convert_to_action(self, command):\r\n        """Convert natural language to action using GPT."""\r\n        prompt = f"""You are a robot controller. Convert the user\'s command into a robot action.\r\n\r\nRobot state:\r\n- Position: {self.robot_state[\'position\']}\r\n- Battery: {self.robot_state[\'battery\']}%\r\n- Status: {self.robot_state[\'status\']}\r\n\r\nUser command: "{command}"\r\n\r\nRespond with JSON only:\r\n{{\r\n    "action": "move|turn|pick|place|stop",\r\n    "parameters": {{...}},\r\n    "confidence": 0.0-1.0\r\n}}\r\n\r\nExamples:\r\n- "move forward" -> {{"action": "move", "parameters": {{"direction": "forward", "distance": 1.0}}, "confidence": 0.9}}\r\n- "turn left 90 degrees" -> {{"action": "turn", "parameters": {{"direction": "left", "angle": 90}}, "confidence": 0.9}}\r\n- "stop" -> {{"action": "stop", "parameters": {{}}, "confidence": 1.0}}\r\n"""\r\n        \r\n        try:\r\n            response = openai.ChatCompletion.create(\r\n                model="gpt-3.5-turbo",  # Cheapest option\r\n                messages=[\r\n                    {"role": "system", "content": "You are a robot action parser. Always respond with valid JSON."},\r\n                    {"role": "user", "content": prompt}\r\n                ],\r\n                temperature=0.3,  # Lower = more deterministic\r\n                max_tokens=150\r\n            )\r\n            \r\n            # Parse response\r\n            text = response.choices[0].message.content.strip()\r\n            \r\n            # Extract JSON (handle markdown code blocks)\r\n            if \'```\' in text:\r\n                text = text.split(\'```\')[1]\r\n                if text.startswith(\'json\'):\r\n                    text = text[4:]\r\n            \r\n            action = json.loads(text)\r\n            return action\r\n        \r\n        except Exception as e:\r\n            self.get_logger().error(f\'Error converting command: {e}\')\r\n            return None\r\n    \r\n    def execute_action(self, action):\r\n        """Execute robot action."""\r\n        action_type = action.get(\'action\')\r\n        params = action.get(\'parameters\', {})\r\n        \r\n        if action_type == \'move\':\r\n            self.execute_move(params)\r\n        elif action_type == \'turn\':\r\n            self.execute_turn(params)\r\n        elif action_type == \'stop\':\r\n            self.execute_stop()\r\n        else:\r\n            self.get_logger().warn(f\'Unknown action: {action_type}\')\r\n    \r\n    def execute_move(self, params):\r\n        """Execute move action."""\r\n        direction = params.get(\'direction\', \'forward\')\r\n        distance = params.get(\'distance\', 1.0)\r\n        \r\n        cmd = Twist()\r\n        if direction == \'forward\':\r\n            cmd.linear.x = 0.5\r\n        elif direction == \'backward\':\r\n            cmd.linear.x = -0.5\r\n        \r\n        self.cmd_vel_pub.publish(cmd)\r\n        self.get_logger().info(f\'Moving {direction} {distance}m\')\r\n    \r\n    def execute_turn(self, params):\r\n        """Execute turn action."""\r\n        direction = params.get(\'direction\', \'left\')\r\n        angle = params.get(\'angle\', 90)\r\n        \r\n        cmd = Twist()\r\n        if direction == \'left\':\r\n            cmd.angular.z = 0.5\r\n        elif direction == \'right\':\r\n            cmd.angular.z = -0.5\r\n        \r\n        self.cmd_vel_pub.publish(cmd)\r\n        self.get_logger().info(f\'Turning {direction} {angle} degrees\')\r\n    \r\n    def execute_stop(self):\r\n        """Execute stop action."""\r\n        cmd = Twist()\r\n        self.cmd_vel_pub.publish(cmd)\r\n        self.get_logger().info(\'Stopping\')\r\n\r\ndef main(args=None):\r\n    rclpy.init(args=args)\r\n    node = LanguageToAction()\r\n    \r\n    try:\r\n        rclpy.spin(node)\r\n    except KeyboardInterrupt:\r\n        node.get_logger().info(\'Shutting down...\')\r\n    finally:\r\n        node.destroy_node()\r\n        rclpy.shutdown()\r\n\r\nif __name__ == \'__main__\':\r\n    main()\n'})}),"\n",(0,o.jsx)(e.h2,{id:"function-calling",children:"Function Calling"}),"\n",(0,o.jsx)(e.p,{children:"Function calling allows GPT to call predefined functions, making it more reliable for robot control."}),"\n",(0,o.jsx)(e.h3,{id:"setup-function-calling",children:"Setup Function Calling"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'#!/usr/bin/env python3\r\n"""\r\nFunction Calling for Robot Control\r\n\r\nUse OpenAI function calling for structured robot commands.\r\n"""\r\n\r\nimport openai\r\nimport rclpy\r\nfrom rclpy.node import Node\r\nfrom std_msgs.msg import String\r\nfrom geometry_msgs.msg import Twist\r\nimport json\r\n\r\nclass FunctionCallingRobot(Node):\r\n    def __init__(self):\r\n        super().__init__(\'function_calling_robot\')\r\n        \r\n        openai.api_key = os.getenv(\'OPENAI_API_KEY\')\r\n        \r\n        # Subscriber\r\n        self.command_sub = self.create_subscription(\r\n            String,\r\n            \'/voice_command\',\r\n            self.command_callback,\r\n            10\r\n        )\r\n        \r\n        # Publisher\r\n        self.cmd_vel_pub = self.create_publisher(Twist, \'/cmd_vel\', 10)\r\n        \r\n        # Define functions\r\n        self.functions = [\r\n            {\r\n                "name": "move_robot",\r\n                "description": "Move the robot in a direction",\r\n                "parameters": {\r\n                    "type": "object",\r\n                    "properties": {\r\n                        "direction": {\r\n                            "type": "string",\r\n                            "enum": ["forward", "backward", "left", "right"],\r\n                            "description": "Direction to move"\r\n                        },\r\n                        "distance": {\r\n                            "type": "number",\r\n                            "description": "Distance in meters"\r\n                        }\r\n                    },\r\n                    "required": ["direction"]\r\n                }\r\n            },\r\n            {\r\n                "name": "turn_robot",\r\n                "description": "Turn the robot",\r\n                "parameters": {\r\n                    "type": "object",\r\n                    "properties": {\r\n                        "direction": {\r\n                            "type": "string",\r\n                            "enum": ["left", "right"],\r\n                            "description": "Turn direction"\r\n                        },\r\n                        "angle": {\r\n                            "type": "number",\r\n                            "description": "Angle in degrees"\r\n                        }\r\n                    },\r\n                    "required": ["direction"]\r\n                }\r\n            },\r\n            {\r\n                "name": "stop_robot",\r\n                "description": "Stop the robot",\r\n                "parameters": {\r\n                    "type": "object",\r\n                    "properties": {}\r\n                }\r\n            }\r\n        ]\r\n        \r\n        self.get_logger().info(\'Function calling robot started\')\r\n    \r\n    def command_callback(self, msg):\r\n        """Process command with function calling."""\r\n        command = msg.data\r\n        \r\n        try:\r\n            response = openai.ChatCompletion.create(\r\n                model="gpt-3.5-turbo",\r\n                messages=[\r\n                    {"role": "system", "content": "You are a robot controller. Use the provided functions to control the robot."},\r\n                    {"role": "user", "content": command}\r\n                ],\r\n                functions=self.functions,\r\n                function_call="auto"\r\n            )\r\n            \r\n            message = response.choices[0].message\r\n            \r\n            # Check if function was called\r\n            if message.get("function_call"):\r\n                function_name = message["function_call"]["name"]\r\n                function_args = json.loads(message["function_call"]["arguments"])\r\n                \r\n                # Execute function\r\n                self.execute_function(function_name, function_args)\r\n            else:\r\n                self.get_logger().info(f\'Response: {message["content"]}\')\r\n        \r\n        except Exception as e:\r\n            self.get_logger().error(f\'Error: {e}\')\r\n    \r\n    def execute_function(self, function_name, args):\r\n        """Execute called function."""\r\n        if function_name == "move_robot":\r\n            self.move_robot(args)\r\n        elif function_name == "turn_robot":\r\n            self.turn_robot(args)\r\n        elif function_name == "stop_robot":\r\n            self.stop_robot()\r\n    \r\n    def move_robot(self, args):\r\n        """Move robot."""\r\n        direction = args.get(\'direction\')\r\n        distance = args.get(\'distance\', 1.0)\r\n        \r\n        cmd = Twist()\r\n        if direction == \'forward\':\r\n            cmd.linear.x = 0.5\r\n        elif direction == \'backward\':\r\n            cmd.linear.x = -0.5\r\n        elif direction == \'left\':\r\n            cmd.angular.z = 0.5\r\n        elif direction == \'right\':\r\n            cmd.angular.z = -0.5\r\n        \r\n        self.cmd_vel_pub.publish(cmd)\r\n        self.get_logger().info(f\'Moving {direction} {distance}m\')\r\n    \r\n    def turn_robot(self, args):\r\n        """Turn robot."""\r\n        direction = args.get(\'direction\')\r\n        angle = args.get(\'angle\', 90)\r\n        \r\n        cmd = Twist()\r\n        if direction == \'left\':\r\n            cmd.angular.z = 0.5\r\n        else:\r\n            cmd.angular.z = -0.5\r\n        \r\n        self.cmd_vel_pub.publish(cmd)\r\n        self.get_logger().info(f\'Turning {direction} {angle} degrees\')\r\n    \r\n    def stop_robot(self):\r\n        """Stop robot."""\r\n        cmd = Twist()\r\n        self.cmd_vel_pub.publish(cmd)\r\n        self.get_logger().info(\'Stopping\')\r\n\r\ndef main(args=None):\r\n    rclpy.init(args=args)\r\n    node = FunctionCallingRobot()\r\n    \r\n    try:\r\n        rclpy.spin(node)\r\n    except KeyboardInterrupt:\r\n        node.get_logger().info(\'Shutting down...\')\r\n    finally:\r\n        node.destroy_node()\r\n        rclpy.shutdown()\r\n\r\nif __name__ == \'__main__\':\r\n    main()\n'})}),"\n",(0,o.jsx)(e.h2,{id:"complete-working-system",children:"Complete Working System"}),"\n",(0,o.jsx)(e.h3,{id:"full-vla-system-with-llm",children:"Full VLA System with LLM"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'#!/usr/bin/env python3\r\n"""\r\nComplete VLA System with LLM\r\n\r\nIntegrates voice, vision, and LLM for complete VLA.\r\n"""\r\n\r\nimport openai\r\nimport rclpy\r\nfrom rclpy.node import Node\r\nfrom std_msgs.msg import String\r\nfrom sensor_msgs.msg import Image\r\nfrom geometry_msgs.msg import Twist\r\nfrom cv_bridge import CvBridge\r\nfrom ultralytics import YOLO\r\nimport json\r\nimport base64\r\nimport io\r\n\r\nclass CompleteVLASystem(Node):\r\n    def __init__(self):\r\n        super().__init__(\'complete_vla_system\')\r\n        \r\n        openai.api_key = os.getenv(\'OPENAI_API_KEY\')\r\n        \r\n        # Components\r\n        self.bridge = CvBridge()\r\n        self.yolo_model = YOLO(\'yolov8n.pt\')\r\n        \r\n        # Subscribers\r\n        self.voice_sub = self.create_subscription(\r\n            String, \'/voice_command\', self.voice_callback, 10\r\n        )\r\n        self.image_sub = self.create_subscription(\r\n            Image, \'/camera/image_raw\', self.image_callback, 10\r\n        )\r\n        \r\n        # Publishers\r\n        self.action_pub = self.create_publisher(String, \'/robot_action\', 10)\r\n        self.cmd_vel_pub = self.create_publisher(Twist, \'/cmd_vel\', 10)\r\n        \r\n        # State\r\n        self.current_image = None\r\n        self.detected_objects = []\r\n        \r\n        self.get_logger().info(\'Complete VLA system started\')\r\n    \r\n    def image_callback(self, msg):\r\n        """Process images."""\r\n        try:\r\n            self.current_image = self.bridge.imgmsg_to_cv2(msg, "bgr8")\r\n            \r\n            # Detect objects\r\n            results = self.yolo_model(self.current_image)\r\n            self.detected_objects = []\r\n            \r\n            for result in results:\r\n                for box in result.boxes:\r\n                    if float(box.conf[0]) > 0.5:\r\n                        self.detected_objects.append({\r\n                            \'label\': self.yolo_model.names[int(box.cls[0])],\r\n                            \'confidence\': float(box.conf[0])\r\n                        })\r\n        \r\n        except Exception as e:\r\n            self.get_logger().error(f\'Image processing error: {e}\')\r\n    \r\n    def voice_callback(self, msg):\r\n        """Process voice commands with vision context."""\r\n        command = msg.data\r\n        self.get_logger().info(f\'Processing: {command}\')\r\n        \r\n        # Create prompt with vision context\r\n        prompt = self.create_multimodal_prompt(command)\r\n        \r\n        # Get LLM response\r\n        action = self.get_llm_action(prompt)\r\n        \r\n        if action:\r\n            self.execute_action(action)\r\n    \r\n    def create_multimodal_prompt(self, command):\r\n        """Create prompt with vision and language."""\r\n        objects_str = \', \'.join([obj[\'label\'] for obj in self.detected_objects])\r\n        \r\n        prompt = f"""You are a robot assistant. The user said: "{command}"\r\n\r\nCurrent scene contains: {objects_str if objects_str else "no detected objects"}\r\n\r\nConvert this to a robot action. Available actions:\r\n- move(direction, distance)\r\n- turn(direction, angle)\r\n- pick(object)\r\n- place(object, location)\r\n- stop()\r\n\r\nRespond with JSON:\r\n{{\r\n    "action": "...",\r\n    "parameters": {{...}},\r\n    "reasoning": "..."\r\n}}"""\r\n        return prompt\r\n    \r\n    def get_llm_action(self, prompt):\r\n        """Get action from LLM."""\r\n        try:\r\n            response = openai.ChatCompletion.create(\r\n                model="gpt-3.5-turbo",\r\n                messages=[\r\n                    {"role": "system", "content": "You are a robot controller. Always respond with valid JSON."},\r\n                    {"role": "user", "content": prompt}\r\n                ],\r\n                temperature=0.3,\r\n                max_tokens=200\r\n            )\r\n            \r\n            text = response.choices[0].message.content.strip()\r\n            \r\n            # Parse JSON\r\n            if \'```\' in text:\r\n                text = text.split(\'```\')[1]\r\n                if text.startswith(\'json\'):\r\n                    text = text[4:]\r\n            \r\n            return json.loads(text)\r\n        \r\n        except Exception as e:\r\n            self.get_logger().error(f\'LLM error: {e}\')\r\n            return None\r\n    \r\n    def execute_action(self, action):\r\n        """Execute action."""\r\n        action_type = action.get(\'action\')\r\n        params = action.get(\'parameters\', {})\r\n        \r\n        self.get_logger().info(f\'Executing: {action_type} with {params}\')\r\n        \r\n        # Execute based on action type\r\n        # (Implementation similar to previous examples)\r\n\r\ndef main(args=None):\r\n    rclpy.init(args=args)\r\n    node = CompleteVLASystem()\r\n    \r\n    try:\r\n        rclpy.spin(node)\r\n    except KeyboardInterrupt:\r\n        node.get_logger().info(\'Shutting down...\')\r\n    finally:\r\n        node.destroy_node()\r\n        rclpy.shutdown()\r\n\r\nif __name__ == \'__main__\':\r\n    main()\n'})}),"\n",(0,o.jsx)(e.h2,{id:"cost-optimization-tips",children:"Cost Optimization Tips"}),"\n",(0,o.jsx)(e.h3,{id:"1-use-gpt-35-turbo",children:"1. Use GPT-3.5-turbo"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'# Cheapest model\r\nmodel = "gpt-3.5-turbo"  # $0.002 per 1K tokens\r\n# Instead of\r\n# model = "gpt-4"  # $0.03 per 1K tokens (15x more expensive)\n'})}),"\n",(0,o.jsx)(e.h3,{id:"2-cache-common-queries",children:"2. Cache Common Queries"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"# Cache responses\r\ncache = {}\r\n\r\ndef get_cached_response(prompt):\r\n    if prompt in cache:\r\n        return cache[prompt]\r\n    \r\n    response = openai.ChatCompletion.create(...)\r\n    cache[prompt] = response\r\n    return response\n"})}),"\n",(0,o.jsx)(e.h3,{id:"3-reduce-token-usage",children:"3. Reduce Token Usage"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'# Use shorter prompts\r\nprompt = f"Command: {command}\\nAction:"  # Short\r\n# Instead of\r\n# prompt = f"Long detailed explanation...{command}..."  # Long\n'})}),"\n",(0,o.jsx)(e.h3,{id:"4-batch-requests",children:"4. Batch Requests"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'# Process multiple commands at once\r\ncommands = ["move forward", "turn left", "stop"]\r\nbatch_prompt = "\\n".join([f"Command {i+1}: {cmd}" for i, cmd in enumerate(commands)])\n'})}),"\n",(0,o.jsx)(e.h3,{id:"5-monitor-usage",children:"5. Monitor Usage"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'# Track API usage\r\ndef track_usage(response):\r\n    tokens_used = response.usage.total_tokens\r\n    cost = tokens_used * 0.002 / 1000  # GPT-3.5-turbo pricing\r\n    print(f"Tokens: {tokens_used}, Cost: ${cost:.4f}")\n'})}),"\n",(0,o.jsx)(e.h2,{id:"performance-benchmarks",children:"Performance Benchmarks"}),"\n",(0,o.jsx)(e.h3,{id:"response-times",children:"Response Times"}),"\n",(0,o.jsxs)(e.table,{children:[(0,o.jsx)(e.thead,{children:(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.th,{children:"Model"}),(0,o.jsx)(e.th,{children:"Latency"}),(0,o.jsx)(e.th,{children:"Cost per 1K tokens"})]})}),(0,o.jsxs)(e.tbody,{children:[(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.td,{children:"GPT-3.5-turbo"}),(0,o.jsx)(e.td,{children:"200-500ms"}),(0,o.jsx)(e.td,{children:"$0.002"})]}),(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.td,{children:"GPT-4"}),(0,o.jsx)(e.td,{children:"500-2000ms"}),(0,o.jsx)(e.td,{children:"$0.03"})]}),(0,o.jsxs)(e.tr,{children:[(0,o.jsx)(e.td,{children:"GPT-4-turbo"}),(0,o.jsx)(e.td,{children:"300-1000ms"}),(0,o.jsx)(e.td,{children:"$0.01"})]})]})]}),"\n",(0,o.jsx)(e.h3,{id:"cost-per-session",children:"Cost per Session"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{children:"Average conversation:\r\n- Input: ~100 tokens\r\n- Output: ~50 tokens\r\n- Cost: ~$0.0003 per conversation\r\n\r\nWith $5 credit: ~16,000 conversations\n"})}),"\n",(0,o.jsx)(e.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Use function calling"}),": More reliable than JSON parsing"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Set temperature low"}),": 0.3 for deterministic responses"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Validate outputs"}),": Always check LLM responses"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Handle errors"}),": Graceful fallback for API failures"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Monitor costs"}),": Track usage to stay within budget"]}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"common-errors-and-solutions",children:"Common Errors and Solutions"}),"\n",(0,o.jsx)(e.h3,{id:"error-1-api-key-not-set",children:'Error 1: "API key not set"'}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"# Solution\r\nimport os\r\nos.environ['OPENAI_API_KEY'] = 'sk-your-key'\n"})}),"\n",(0,o.jsx)(e.h3,{id:"error-2-rate-limit-exceeded",children:'Error 2: "Rate limit exceeded"'}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"# Solution: Add retry logic\r\nimport time\r\n\r\ndef call_with_retry(prompt, max_retries=3):\r\n    for i in range(max_retries):\r\n        try:\r\n            return openai.ChatCompletion.create(...)\r\n        except openai.error.RateLimitError:\r\n            time.sleep(2 ** i)  # Exponential backoff\n"})}),"\n",(0,o.jsx)(e.h3,{id:"error-3-invalid-json-response",children:'Error 3: "Invalid JSON response"'}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"# Solution: Use function calling or add JSON extraction\r\nimport re\r\n\r\ndef extract_json(text):\r\n    # Try to find JSON in response\r\n    json_match = re.search(r'\\{.*\\}', text, re.DOTALL)\r\n    if json_match:\r\n        return json.loads(json_match.group())\r\n    return None\n"})}),"\n",(0,o.jsx)(e.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,o.jsx)(e.p,{children:"Continue learning:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.a,{href:"/physical-ai-textbook/docs/module-04-vla/action-planning",children:"Chapter 4: Action Planning"})," - Plan complex tasks"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.a,{href:"/physical-ai-textbook/docs/module-04-vla/multimodal",children:"Chapter 5: Multimodal Systems"})," - Complete pipeline"]}),"\n"]})]})}function p(n={}){const{wrapper:e}={...(0,s.R)(),...n.components};return e?(0,o.jsx)(e,{...n,children:(0,o.jsx)(d,{...n})}):d(n)}},8453:(n,e,r)=>{r.d(e,{R:()=>i,x:()=>a});var t=r(6540);const o={},s=t.createContext(o);function i(n){const e=t.useContext(s);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function a(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(o):n.components||o:i(n.components),t.createElement(s.Provider,{value:e},n.children)}}}]);