---
sidebar_position: 1
---

# Module 4: Vision-Language-Action (VLA)

Welcome to Module 4! This module covers Vision-Language-Action (VLA) systems using **FREE** tools. Learn to build robots that understand natural language with a budget of just **$5**!

## Learning Objectives

By the end of this module, you will be able to:

- Understand VLA architectures
- Implement free voice recognition
- Integrate LLMs with robots ($5 OpenAI credit)
- Plan and execute actions from language
- Build complete multimodal systems
- Deploy autonomous VLA robots

## Module Structure

This module consists of 6 chapters:

1. **VLA Introduction** - What is VLA and free tools
2. **Voice Commands** - Free speech recognition
3. **LLM Integration** - OpenAI API setup ($5)
4. **Action Planning** - Task decomposition
5. **Multimodal Systems** - Vision + Language + Action
6. **Capstone Project** - Complete autonomous butler

## Prerequisites

- Completion of Module 1 (ROS 2)
- Completion of Module 2 (Simulation)
- Completion of Module 3 (Perception)
- Basic Python knowledge
- **Budget: $5 total** (OpenAI free credit)

## All Tools Are FREE (or $5)

- ✅ Web Speech API: **Free**
- ✅ OpenAI Whisper: **Free tier**
- ✅ OpenAI GPT: **$5 free credit**
- ✅ OpenCV: **Free**
- ✅ ROS 2: **Free**

**Total Cost: $5 (one-time, for learning)**

Let's build amazing VLA robots for free!

